{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2da463b6-106d-4313-a900-ce58d8a89f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c289ee63-c73f-4d03-8852-5ffc5800156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e6ccddaa-57c8-42ca-aa67-93f5c4fda0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Point A   Point B   Point C   Point D   Point E  \\\n",
       "0             0  1.373475  0.958978  0.836790  1.502963  0.978804   \n",
       "1             1  1.940213  1.371291  1.743612  1.315589  2.017418   \n",
       "2             2  1.690368  2.025028  2.025214  1.518278  1.934396   \n",
       "3             3  1.542669  1.888478  1.641450  1.641526  2.550871   \n",
       "4             4  1.429971  1.580948  1.820888  1.274735  1.757213   \n",
       "..          ...       ...       ...       ...       ...       ...   \n",
       "306         306  0.234889  0.341797  0.312052  0.323540  0.359836   \n",
       "307         307  0.235683  0.339810  0.340483  0.328003  0.329723   \n",
       "308         308  0.231840  0.313921  0.329652  0.349243  0.341359   \n",
       "309         309  0.237851  0.306959  0.316966  0.357427  0.358833   \n",
       "310         310  0.234731  0.343230  0.315228  0.321040  0.357567   \n",
       "\n",
       "     Error Classification  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "306                     4  \n",
       "307                     4  \n",
       "308                     4  \n",
       "309                     4  \n",
       "310                     4  \n",
       "\n",
       "[311 rows x 7 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/dataset_with_error_cnn.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3cdb1609-b277-48fb-be6f-9a9c82b8fa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point A   Point B   Point C   Point D   Point E  Error Classification\n",
       "0    1.373475  0.958978  0.836790  1.502963  0.978804                     0\n",
       "1    1.940213  1.371291  1.743612  1.315589  2.017418                     1\n",
       "2    1.690368  2.025028  2.025214  1.518278  1.934396                     0\n",
       "3    1.542669  1.888478  1.641450  1.641526  2.550871                     1\n",
       "4    1.429971  1.580948  1.820888  1.274735  1.757213                     0\n",
       "..        ...       ...       ...       ...       ...                   ...\n",
       "306  0.234889  0.341797  0.312052  0.323540  0.359836                     4\n",
       "307  0.235683  0.339810  0.340483  0.328003  0.329723                     4\n",
       "308  0.231840  0.313921  0.329652  0.349243  0.341359                     4\n",
       "309  0.237851  0.306959  0.316966  0.357427  0.358833                     4\n",
       "310  0.234731  0.343230  0.315228  0.321040  0.357567                     4\n",
       "\n",
       "[311 rows x 6 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4e06b401-87b4-49e8-9216-ce54b244932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Error Classification',axis=1)\n",
    "\n",
    "y = df['Error Classification']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "69bc23cb-eee6-4c28-90a8-f5257f3821b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(5, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(5, activation = 'linear', name = \"L2\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ad6e20c0-cb8e-4ba4-934d-e5fccceef436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4142 - accuracy: 0.2627\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3471 - accuracy: 0.2673\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3033 - accuracy: 0.2765\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2629 - accuracy: 0.5253\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2179 - accuracy: 0.5346\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1585 - accuracy: 0.5392\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1062 - accuracy: 0.5668\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0611 - accuracy: 0.5853\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0192 - accuracy: 0.6820\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 984us/step - loss: 0.9774 - accuracy: 0.7788\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9421 - accuracy: 0.7972\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 970us/step - loss: 0.9031 - accuracy: 0.7972\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8694 - accuracy: 0.8018\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 988us/step - loss: 0.8334 - accuracy: 0.7972\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 984us/step - loss: 0.8028 - accuracy: 0.7972\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.8018\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7464 - accuracy: 0.8065\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.7972\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.8065\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.8065\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.8065\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.8018\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.8065\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5999 - accuracy: 0.8018\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.8065\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.8203\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.8157\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 987us/step - loss: 0.5430 - accuracy: 0.8111\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 994us/step - loss: 0.5322 - accuracy: 0.8111\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8341\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.8387\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 987us/step - loss: 0.5026 - accuracy: 0.8479\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 907us/step - loss: 0.4921 - accuracy: 0.8433\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.8433\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 989us/step - loss: 0.4755 - accuracy: 0.8525\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.8618\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8618\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 991us/step - loss: 0.4537 - accuracy: 0.8664\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.8756\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.4397 - accuracy: 0.8710\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8756\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8756\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8802\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 838us/step - loss: 0.4159 - accuracy: 0.8802\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8802\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 987us/step - loss: 0.4088 - accuracy: 0.8802\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 995us/step - loss: 0.4065 - accuracy: 0.8756\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8802\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8802\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8802\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 916us/step - loss: 0.3817 - accuracy: 0.8802\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8802\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8756\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8756\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8756\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.3628 - accuracy: 0.8802\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 995us/step - loss: 0.3603 - accuracy: 0.8756\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8756\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8756\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8756\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8756\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8756\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 980us/step - loss: 0.3397 - accuracy: 0.8756\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8756\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8756\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8802\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8802\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8756\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8756\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8802\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8802\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8848\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3137 - accuracy: 0.8802\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8802\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8848\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8802\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8756\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8848\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8802\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8848\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8848\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8802\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8802\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8802\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 983us/step - loss: 0.2866 - accuracy: 0.8802\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2852 - accuracy: 0.8802\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.8986\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8894\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.8986\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2776 - accuracy: 0.9171\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.9171\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 991us/step - loss: 0.2750 - accuracy: 0.9171\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.9032\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9217\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.9263\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.9217\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 912us/step - loss: 0.2673 - accuracy: 0.9217\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.9263\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 887us/step - loss: 0.2649 - accuracy: 0.9217\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.9309\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.9263\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.9217\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.9217\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.9263\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 987us/step - loss: 0.2565 - accuracy: 0.9171\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9217\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.9309\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.9309\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.9355\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.9309\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.9263\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9263\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9309\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9401\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 993us/step - loss: 0.2453 - accuracy: 0.9401\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.9355\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 995us/step - loss: 0.2435 - accuracy: 0.9447\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9401\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9263\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9355\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9447\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9355\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 986us/step - loss: 0.2372 - accuracy: 0.9355\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9355\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.9401\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9447\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 987us/step - loss: 0.2341 - accuracy: 0.9447\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9447\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 990us/step - loss: 0.2345 - accuracy: 0.9493\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9447\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.9447\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9401\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9447\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9401\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9447\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9447\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9401\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9401\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9447\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9447\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9447\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9447\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9447\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9401\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 992us/step - loss: 0.2203 - accuracy: 0.9493\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9493\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9539\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9447\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9447\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9493\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9493\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9493\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 992us/step - loss: 0.2169 - accuracy: 0.9493\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9539\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 994us/step - loss: 0.2173 - accuracy: 0.9539\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9539\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.9447\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.9447\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 996us/step - loss: 0.2135 - accuracy: 0.9539\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9539\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 983us/step - loss: 0.2134 - accuracy: 0.9493\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.9447\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9493\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9539\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9539\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9539\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.9493\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9539\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.9493\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9493\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9493\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9539\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9539\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9539\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9539\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9493\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9539\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 992us/step - loss: 0.2043 - accuracy: 0.9539\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.9539\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9493\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9539\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9539\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 913us/step - loss: 0.2027 - accuracy: 0.9539\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9493\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9493\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9539\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.9539\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9539\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9493\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9539\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9539\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9539\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9493\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9539\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9493\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 992us/step - loss: 0.1982 - accuracy: 0.9539\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9493\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9539\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9493\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ee6c403d0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d7f4e10b-81c0-4f71-8f76-3070c9cb9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020EE6C55D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bbb6b80b-49b2-4bf6-b475-44ab7aa354c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 5)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5f24449-a016-42a7-a8e6-231101faf324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 2.59292412e+00,  1.89523053e+00,  2.63979387e+00,\n",
       "        -4.30193424e+00, -1.91907139e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 5.36647415e+00,  3.03276324e+00,  6.03959322e+00,\n",
       "        -5.90760994e+00, -2.87835674e+01],\n",
       "       [-1.36371374e+01, -7.94364214e+00, -3.02256012e+00,\n",
       "         1.06638451e+01, -2.78412647e+01],\n",
       "       [ 3.99398565e+00,  1.77400327e+00,  7.46926355e+00,\n",
       "        -3.89514613e+00, -3.82025719e+01],\n",
       "       [-6.03048658e+00, -3.47841120e+00,  2.84290314e-01,\n",
       "         3.90529847e+00, -2.67595673e+01],\n",
       "       [-7.60667133e+00, -4.65369654e+00,  7.17319965e-01,\n",
       "         5.74336910e+00, -3.20739403e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-7.32883096e-01, -1.11095238e+00,  5.90721178e+00,\n",
       "         4.97581959e-01, -4.11182709e+01],\n",
       "       [-8.64464092e+00, -5.11784744e+00, -3.83091450e-01,\n",
       "         6.41155815e+00, -2.92665234e+01],\n",
       "       [ 5.27902412e+00,  3.00394511e+00,  5.90087748e+00,\n",
       "        -5.86931896e+00, -2.83376217e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.51800327e+01, -9.32294083e+00, -1.57526350e+00,\n",
       "         1.28636055e+01, -3.77019501e+01],\n",
       "       [ 2.43807745e+00,  2.06774139e+00,  1.39443827e+00,\n",
       "        -4.62537527e+00, -1.38503265e+01],\n",
       "       [-2.63954115e+00, -2.81181216e+00,  7.67950010e+00,\n",
       "         3.20962024e+00, -5.32298813e+01],\n",
       "       [-8.12954426e+00, -5.34744024e+00,  2.21993208e+00,\n",
       "         6.88494587e+00, -4.00228577e+01],\n",
       "       [ 4.51498866e-01,  8.73089671e-01,  6.58255577e-01,\n",
       "        -2.81041455e+00, -1.47129574e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.33838854e+01, -8.21730042e+00, -1.02371359e+00,\n",
       "         1.11779861e+01, -3.64028015e+01],\n",
       "       [ 2.67292929e+00,  2.08691502e+00,  2.02734470e+00,\n",
       "        -4.62631083e+00, -1.62331619e+01],\n",
       "       [-8.30942249e+00, -5.04701281e+00,  3.25895786e-01,\n",
       "         6.33414555e+00, -3.17827854e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.78061604e-01, -6.83630943e-01,  5.69388056e+00,\n",
       "        -1.73258305e-01, -3.89703636e+01],\n",
       "       [ 2.96602964e+00,  2.24172258e+00,  2.23189974e+00,\n",
       "        -4.85654545e+00, -1.65425987e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 4.46653724e-01,  1.41148901e+00, -1.76444888e+00,\n",
       "        -3.75340533e+00, -3.69513941e+00],\n",
       "       [ 6.06240630e-01, -1.08902454e-01,  5.52352858e+00,\n",
       "        -1.07021642e+00, -3.65313454e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 8.91959667e-02,  1.29369259e+00, -2.33146477e+00,\n",
       "        -3.59688807e+00, -1.87229824e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.06902468e+00, -1.32257915e+00,  5.82505941e+00,\n",
       "         8.21283817e-01, -4.14573021e+01],\n",
       "       [-1.37507057e+01, -8.53914452e+00, -7.06826210e-01,\n",
       "         1.16903315e+01, -3.86233253e+01],\n",
       "       [-1.82579756e-02,  1.25828230e+00, -2.50191307e+00,\n",
       "        -3.54983807e+00, -1.32434082e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-6.16060019e+00, -3.62047195e+00,  5.21473885e-01,\n",
       "         4.13586330e+00, -2.81152058e+01],\n",
       "       [-8.18346786e+00, -5.35600996e+00,  2.09324837e+00,\n",
       "         6.89245415e+00, -3.95605774e+01],\n",
       "       [-5.43168449e+00, -3.45067167e+00,  1.99258852e+00,\n",
       "         3.93992496e+00, -3.32655907e+01],\n",
       "       [-1.55231476e+01, -9.40520096e+00, -2.25731802e+00,\n",
       "         1.29599180e+01, -3.53250351e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-7.35254097e+00, -4.90803003e+00,  2.63241816e+00,\n",
       "         6.22380829e+00, -4.02523918e+01],\n",
       "       [ 5.55293798e+00,  3.09421039e+00,  6.33537149e+00,\n",
       "        -5.98925543e+00, -2.97344341e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 3.98787260e+00,  1.98447156e+00,  6.50928164e+00,\n",
       "        -4.26436138e+00, -3.38457222e+01],\n",
       "       [ 1.07735527e+00, -6.89053535e-02,  6.78627729e+00,\n",
       "        -1.07478094e+00, -4.12800751e+01],\n",
       "       [ 6.48628116e-01, -4.17894840e-01,  7.03513956e+00,\n",
       "        -5.23523808e-01, -4.33222542e+01],\n",
       "       [-1.16032639e+01, -6.49800730e+00, -3.26412344e+00,\n",
       "         8.41617775e+00, -2.24276428e+01],\n",
       "       [-1.26118889e+01, -7.99190378e+00,  3.30581665e-01,\n",
       "         1.08907242e+01, -4.09300461e+01],\n",
       "       [-1.33161316e+01, -8.39883232e+00, -4.52613831e-03,\n",
       "         1.15051184e+01, -4.08984070e+01],\n",
       "       [-8.90151620e-01, -1.33302021e+00,  6.41911650e+00,\n",
       "         8.64404917e-01, -4.37820282e+01],\n",
       "       [-1.18491478e+01, -6.72433138e+00, -3.00435305e+00,\n",
       "         8.77814007e+00, -2.41316547e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 9.79716778e-02,  1.29658461e+00, -2.31754422e+00,\n",
       "        -3.60073066e+00, -1.91704941e+00],\n",
       "       [-1.66662467e+00, -1.85019493e+00,  6.35603380e+00,\n",
       "         1.66172004e+00, -4.51418495e+01],\n",
       "       [-1.03779221e+01, -6.01524782e+00, -1.67357063e+00,\n",
       "         7.74144745e+00, -2.70687428e+01],\n",
       "       [-1.33462086e+01, -7.94815397e+00, -2.11212349e+00,\n",
       "         1.07121534e+01, -3.13684597e+01],\n",
       "       [ 3.51573181e+00,  2.42287087e+00,  3.10386229e+00,\n",
       "        -5.09723949e+00, -1.93457813e+01],\n",
       "       [-5.23782063e+00, -3.04261732e+00,  7.60883331e-01,\n",
       "         3.25266814e+00, -2.72476883e+01],\n",
       "       [-7.70843315e+00, -4.34479284e+00, -9.75583553e-01,\n",
       "         5.18858433e+00, -2.45837288e+01],\n",
       "       [-4.28591108e+00, -2.96051717e+00,  3.30659151e+00,\n",
       "         3.24119830e+00, -3.68166046e+01],\n",
       "       [-7.06246495e-01, -1.03505731e+00,  5.64929438e+00,\n",
       "         3.68448973e-01, -3.98877373e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.36071510e+01, -7.67936373e+00, -4.11273527e+00,\n",
       "         1.02054634e+01, -2.28152142e+01],\n",
       "       [-9.49173737e+00, -5.99525595e+00,  9.48782444e-01,\n",
       "         7.82955074e+00, -3.71259499e+01],\n",
       "       [-4.67345536e-01,  1.11029029e+00, -3.21427631e+00,\n",
       "        -3.35319948e+00,  9.65763569e-01],\n",
       "       [ 3.75989056e+00,  2.26987696e+00,  4.53523016e+00,\n",
       "        -4.79555130e+00, -2.53434544e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 1.97299361e-01,  1.32931685e+00, -2.15998626e+00,\n",
       "        -3.64422250e+00, -2.42356682e+00],\n",
       "       [-6.49636221e+00, -4.22394705e+00,  2.19294453e+00,\n",
       "         5.14543915e+00, -3.64358788e+01],\n",
       "       [-1.42003431e+01, -8.86283684e+00, -6.35081768e-01,\n",
       "         1.21944075e+01, -3.99036255e+01],\n",
       "       [-9.30820560e+00, -5.60713816e+00, -2.25375175e-01,\n",
       "         7.17575264e+00, -3.13919201e+01],\n",
       "       [ 1.56892538e-02,  1.26946926e+00, -2.44806433e+00,\n",
       "        -3.56470227e+00, -1.49745321e+00],\n",
       "       [-9.42715549e+00, -6.39022350e+00,  2.91281605e+00,\n",
       "         8.52980232e+00, -4.59292030e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-7.62288904e+00, -5.18014383e+00,  3.02211571e+00,\n",
       "         6.66251564e+00, -4.25997200e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-1.21586695e+01, -7.32072592e+00, -1.28425169e+00,\n",
       "         9.77896881e+00, -3.26180420e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 4.26659107e+00,  2.67030859e+00,  4.29490995e+00,\n",
       "        -5.42601252e+00, -2.31747589e+01],\n",
       "       [-1.30437126e+01, -7.65870905e+00, -2.48095512e+00,\n",
       "         1.02475786e+01, -2.90479259e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [ 2.37924218e-01,  1.34270442e+00, -2.09554529e+00,\n",
       "        -3.66201067e+00, -2.63073158e+00],\n",
       "       [ 2.01816416e+00,  1.83832335e+00,  1.13551092e+00,\n",
       "        -4.28217030e+00, -1.35623703e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-6.21095896e-02, -6.01692200e-01,  5.68224764e+00,\n",
       "        -3.00562382e-01, -3.86714668e+01],\n",
       "       [-1.17213023e+00,  8.78036022e-01, -4.33223772e+00,\n",
       "        -3.04460073e+00,  4.55978537e+00],\n",
       "       [-4.89175129e+00, -2.72398329e+00,  3.94846439e-01,\n",
       "         2.74305797e+00, -2.48474541e+01],\n",
       "       [-1.12274199e+01, -6.92990828e+00, -1.82438850e-01,\n",
       "         9.22430515e+00, -3.56581993e+01]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7c2f6-5c43-4165-9e06-bfac07a86058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4b3e5-c2ef-4552-be07-5c725ad8316c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd10644-9c9c-4f0d-b418-e3d16134a62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "95db886e-70ef-442a-9c11-136312c71536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries that we will be using for building the neural network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "81f920a7-e4e3-44e7-a0d3-0cb0d1744e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the classes for building the neural network layers\n",
    "from tensorflow.keras.layers import Dense,Input,Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c518c338-bbc2-4aac-a4fa-3f28c76a3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialiezer=tf.keras.initializers.RandomUniform(minval=0.0005, maxval=1, seed=100)\n",
    "\n",
    "input1= Input(shape=1)\n",
    "input2= Input(shape=1)\n",
    "input3= Input(shape=1)\n",
    "input4= Input(shape=1)\n",
    "input5= Input(shape=1)\n",
    "\n",
    "l1=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(input1)\n",
    "l1=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(l1)\n",
    "\n",
    "l2=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(input2)\n",
    "l2=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(l2)\n",
    "\n",
    "concatted = Concatenate()([l1, l2])\n",
    "out=Dense(units=1,use_bias=True,activation='sigmoid',kernel_initializer=initialiezer)(concatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b41c4c6b-c74c-4172-b69c-4c27dfd78edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c36f426d-585a-4f5c-a65a-3ab7401bd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model([input1,input2,input3,input4,input5],[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c22dfb14-5bb4-4a5e-9cd1-6f3fff781f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "19172477-93a2-43a9-9a29-ad87e671c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Point A   Point B   Point C   Point D   Point E  \\\n",
       "0             0  1.373475  0.958978  0.836790  1.502963  0.978804   \n",
       "1             1  1.940213  1.371291  1.743612  1.315589  2.017418   \n",
       "2             2  1.690368  2.025028  2.025214  1.518278  1.934396   \n",
       "3             3  1.542669  1.888478  1.641450  1.641526  2.550871   \n",
       "4             4  1.429971  1.580948  1.820888  1.274735  1.757213   \n",
       "..          ...       ...       ...       ...       ...       ...   \n",
       "306         306  0.234889  0.341797  0.312052  0.323540  0.359836   \n",
       "307         307  0.235683  0.339810  0.340483  0.328003  0.329723   \n",
       "308         308  0.231840  0.313921  0.329652  0.349243  0.341359   \n",
       "309         309  0.237851  0.306959  0.316966  0.357427  0.358833   \n",
       "310         310  0.234731  0.343230  0.315228  0.321040  0.357567   \n",
       "\n",
       "     Error Classification  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "306                     4  \n",
       "307                     4  \n",
       "308                     4  \n",
       "309                     4  \n",
       "310                     4  \n",
       "\n",
       "[311 rows x 7 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "inputDataFrame=pandas.read_csv(\"../dataset/dataset_with_error_cnn.csv\")\n",
    "inputDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0acd2d71-39cf-47a7-b405-26391db4a7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point A   Point B   Point C   Point D   Point E  Error Classification\n",
       "0    1.373475  0.958978  0.836790  1.502963  0.978804                     0\n",
       "1    1.940213  1.371291  1.743612  1.315589  2.017418                     1\n",
       "2    1.690368  2.025028  2.025214  1.518278  1.934396                     0\n",
       "3    1.542669  1.888478  1.641450  1.641526  2.550871                     1\n",
       "4    1.429971  1.580948  1.820888  1.274735  1.757213                     0\n",
       "..        ...       ...       ...       ...       ...                   ...\n",
       "306  0.234889  0.341797  0.312052  0.323540  0.359836                     4\n",
       "307  0.235683  0.339810  0.340483  0.328003  0.329723                     4\n",
       "308  0.231840  0.313921  0.329652  0.349243  0.341359                     4\n",
       "309  0.237851  0.306959  0.316966  0.357427  0.358833                     4\n",
       "310  0.234731  0.343230  0.315228  0.321040  0.357567                     4\n",
       "\n",
       "[311 rows x 6 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDataFrame = inputDataFrame.drop('Unnamed: 0', axis=1)\n",
    "inputDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7cfca-edad-4a01-819e-005c84df144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8e520853-0d5a-4625-86be-e68a8f67ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data out as numpy arrays\n",
    "x1s=inputDataFrame['Point A'].to_numpy()\n",
    "x2s=inputDataFrame['Point B'].to_numpy()\n",
    "x3s=inputDataFrame['Point C'].to_numpy()\n",
    "x4s=inputDataFrame['Point D'].to_numpy()\n",
    "x5s=inputDataFrame['Point E'].to_numpy()\n",
    "ys=inputDataFrame['Error Classification'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d0b1235a-01b4-4b15-a964-e46fffdde6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1s=x1s.reshape(x1s.shape[0],1)\n",
    "x2s=x2s.reshape(x2s.shape[0],1)\n",
    "x3s=x3s.reshape(x3s.shape[0],1)\n",
    "x4s=x4s.reshape(x4s.shape[0],1)\n",
    "x5s=x5s.reshape(x5s.shape[0],1)\n",
    "ys=ys.reshape(ys.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "16ec04b5-e74e-4bdd-a4e7-20aa8d25e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1Train, x1Test, x2Train, x2Test, x3Train, x3Test, x4Train, x4Test, x5Train, x5Test, yTrain, yTest = train_test_split(x1s,x2s,x3s,x4s,x5s,ys, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "44d78994-105a-4afa-a231-e5b31fb23647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of x1Train = (248, 1)\n",
      "the shape of x1Test = (63, 1)\n",
      "the shape of x2Train = (248, 1)\n",
      "the shape of x2Test = (63, 1)\n",
      "the shape of x3Train = (248, 1)\n",
      "the shape of x3Test = (63, 1)\n",
      "the shape of x4Train = (248, 1)\n",
      "the shape of x4Test = (63, 1)\n",
      "the shape of x5Train = (248, 1)\n",
      "the shape of x5Test = (63, 1)\n",
      "the shape of yTrain = (248, 1)\n",
      "the shape of yTest = (63, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'the shape of x1Train = {x1Train.shape}')\n",
    "print(f'the shape of x1Test = {x1Test.shape}')\n",
    "\n",
    "print(f'the shape of x2Train = {x5Train.shape}')\n",
    "print(f'the shape of x2Test = {x5Test.shape}')\n",
    "\n",
    "print(f'the shape of x3Train = {x5Train.shape}')\n",
    "print(f'the shape of x3Test = {x5Test.shape}')\n",
    "\n",
    "print(f'the shape of x4Train = {x5Train.shape}')\n",
    "print(f'the shape of x4Test = {x5Test.shape}')\n",
    "\n",
    "print(f'the shape of x5Train = {x5Train.shape}')\n",
    "print(f'the shape of x5Test = {x5Test.shape}')\n",
    "\n",
    "\n",
    "print(f'the shape of yTrain = {yTrain.shape}')\n",
    "print(f'the shape of yTest = {yTest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "57fc65ca-6e78-4dbb-85f6-477e9845d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',metrics=['mse'],optimizer=tf.optimizers.Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "de093d4a-1694-41d8-9ce8-ee908193fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "#     metrics = ['accuracy']\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b070f7f5-db02-4a6e-a927-f650b35b8cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 4.6377 - mse: 4.6377 - val_loss: 4.1628 - val_mse: 4.1628\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5607 - mse: 4.5607 - val_loss: 4.1011 - val_mse: 4.1011\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4884 - mse: 4.4884 - val_loss: 4.0452 - val_mse: 4.0452\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4223 - mse: 4.4223 - val_loss: 3.9959 - val_mse: 3.9959\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3636 - mse: 4.3636 - val_loss: 3.9536 - val_mse: 3.9536\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3128 - mse: 4.3128 - val_loss: 3.9184 - val_mse: 3.9184\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2701 - mse: 4.2701 - val_loss: 3.8897 - val_mse: 3.8897\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2351 - mse: 4.2351 - val_loss: 3.8670 - val_mse: 3.8670\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2070 - mse: 4.2070 - val_loss: 3.8492 - val_mse: 3.8492\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1849 - mse: 4.1849 - val_loss: 3.8357 - val_mse: 3.8357\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1679 - mse: 4.1679 - val_loss: 3.8254 - val_mse: 3.8254\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1549 - mse: 4.1549 - val_loss: 3.8177 - val_mse: 3.8177\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1450 - mse: 4.1450 - val_loss: 3.8119 - val_mse: 3.8119\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1376 - mse: 4.1376 - val_loss: 3.8077 - val_mse: 3.8077\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1320 - mse: 4.1320 - val_loss: 3.8045 - val_mse: 3.8045\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1278 - mse: 4.1278 - val_loss: 3.8021 - val_mse: 3.8021\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1246 - mse: 4.1246 - val_loss: 3.8003 - val_mse: 3.8003\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1222 - mse: 4.1222 - val_loss: 3.7989 - val_mse: 3.7989\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1204 - mse: 4.1204 - val_loss: 3.7979 - val_mse: 3.7979\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1190 - mse: 4.1190 - val_loss: 3.7971 - val_mse: 3.7971\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1179 - mse: 4.1179 - val_loss: 3.7965 - val_mse: 3.7965\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1171 - mse: 4.1171 - val_loss: 3.7960 - val_mse: 3.7960\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1164 - mse: 4.1164 - val_loss: 3.7956 - val_mse: 3.7956\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1159 - mse: 4.1159 - val_loss: 3.7953 - val_mse: 3.7953\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1155 - mse: 4.1155 - val_loss: 3.7951 - val_mse: 3.7951\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1151 - mse: 4.1151 - val_loss: 3.7949 - val_mse: 3.7949\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1148 - mse: 4.1148 - val_loss: 3.7948 - val_mse: 3.7948\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1146 - mse: 4.1146 - val_loss: 3.7946 - val_mse: 3.7946\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1144 - mse: 4.1144 - val_loss: 3.7945 - val_mse: 3.7945\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1143 - mse: 4.1143 - val_loss: 3.7944 - val_mse: 3.7944\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1141 - mse: 4.1141 - val_loss: 3.7944 - val_mse: 3.7944\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1140 - mse: 4.1140 - val_loss: 3.7943 - val_mse: 3.7943\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1139 - mse: 4.1139 - val_loss: 3.7942 - val_mse: 3.7942\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1138 - mse: 4.1138 - val_loss: 3.7942 - val_mse: 3.7942\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1138 - mse: 4.1138 - val_loss: 3.7942 - val_mse: 3.7942\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1137 - mse: 4.1137 - val_loss: 3.7941 - val_mse: 3.7941\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1137 - mse: 4.1137 - val_loss: 3.7941 - val_mse: 3.7941\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1136 - mse: 4.1136 - val_loss: 3.7941 - val_mse: 3.7941\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1136 - mse: 4.1136 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n"
     ]
    }
   ],
   "source": [
    "# train the model. just run a few epochs for this test run. you can adjust later.\n",
    "history=model.fit(x=[x1Train,x2Train,x3Train,x4Train,x5Train],y=[yTrain],validation_data=([x1Test,x2Test,x3Test,x4Test,x5Test],[yTest]),batch_size=256, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6a74b73d-a935-4795-95bd-ec067da459c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "input=[x1Test[60],x2Test[60],x3Test[60],x4Test[60],x4Test[60]]\n",
    "output=model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3ad62dad-b2dd-4eb0-b4ef-ea276d76a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.78251585]),\n",
       " array([2.98232124]),\n",
       " array([2.37517084]),\n",
       " array([2.83734284]),\n",
       " array([2.83734284])]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bf4e1347-bfd3-41ca-bb38-4796a0cc9a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b9e49fd0-f811-4471-a1ef-394741df8d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34060b4-bf10-41eb-96e3-e4f9684598b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpds",
   "language": "python",
   "name": "mlpds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
