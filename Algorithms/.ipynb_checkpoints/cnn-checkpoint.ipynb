{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2da463b6-106d-4313-a900-ce58d8a89f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c289ee63-c73f-4d03-8852-5ffc5800156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6ccddaa-57c8-42ca-aa67-93f5c4fda0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Point A   Point B   Point C   Point D   Point E  \\\n",
       "0             0  1.373475  0.958978  0.836790  1.502963  0.978804   \n",
       "1             1  1.940213  1.371291  1.743612  1.315589  2.017418   \n",
       "2             2  1.690368  2.025028  2.025214  1.518278  1.934396   \n",
       "3             3  1.542669  1.888478  1.641450  1.641526  2.550871   \n",
       "4             4  1.429971  1.580948  1.820888  1.274735  1.757213   \n",
       "..          ...       ...       ...       ...       ...       ...   \n",
       "306         306  0.234889  0.341797  0.312052  0.323540  0.359836   \n",
       "307         307  0.235683  0.339810  0.340483  0.328003  0.329723   \n",
       "308         308  0.231840  0.313921  0.329652  0.349243  0.341359   \n",
       "309         309  0.237851  0.306959  0.316966  0.357427  0.358833   \n",
       "310         310  0.234731  0.343230  0.315228  0.321040  0.357567   \n",
       "\n",
       "     Error Classification  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "306                     4  \n",
       "307                     4  \n",
       "308                     4  \n",
       "309                     4  \n",
       "310                     4  \n",
       "\n",
       "[311 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/dataset_with_error_cnn.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3cdb1609-b277-48fb-be6f-9a9c82b8fa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point A   Point B   Point C   Point D   Point E  Error Classification\n",
       "0    1.373475  0.958978  0.836790  1.502963  0.978804                     0\n",
       "1    1.940213  1.371291  1.743612  1.315589  2.017418                     1\n",
       "2    1.690368  2.025028  2.025214  1.518278  1.934396                     0\n",
       "3    1.542669  1.888478  1.641450  1.641526  2.550871                     1\n",
       "4    1.429971  1.580948  1.820888  1.274735  1.757213                     0\n",
       "..        ...       ...       ...       ...       ...                   ...\n",
       "306  0.234889  0.341797  0.312052  0.323540  0.359836                     4\n",
       "307  0.235683  0.339810  0.340483  0.328003  0.329723                     4\n",
       "308  0.231840  0.313921  0.329652  0.349243  0.341359                     4\n",
       "309  0.237851  0.306959  0.316966  0.357427  0.358833                     4\n",
       "310  0.234731  0.343230  0.315228  0.321040  0.357567                     4\n",
       "\n",
       "[311 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e06b401-87b4-49e8-9216-ce54b244932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Error Classification',axis=1)\n",
    "\n",
    "y = df['Error Classification']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69bc23cb-eee6-4c28-90a8-f5257f3821b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(4, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(5, activation = 'linear', name = \"L2\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad6e20c0-cb8e-4ba4-934d-e5fccceef436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5591 - accuracy: 0.2811\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4834 - accuracy: 0.2811\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4300 - accuracy: 0.2811\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3892 - accuracy: 0.3502\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 991us/step - loss: 1.3503 - accuracy: 0.5069\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3105 - accuracy: 0.5300\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2726 - accuracy: 0.5392\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 872us/step - loss: 1.2328 - accuracy: 0.5392\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1957 - accuracy: 0.5392\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 989us/step - loss: 1.1613 - accuracy: 0.5392\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1325 - accuracy: 0.5438\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1037 - accuracy: 0.5438\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 991us/step - loss: 1.0802 - accuracy: 0.5438\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0574 - accuracy: 0.5438\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 988us/step - loss: 1.0389 - accuracy: 0.5438\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0195 - accuracy: 0.5438\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0029 - accuracy: 0.5714\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9871 - accuracy: 0.5760\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9704 - accuracy: 0.5668\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9565 - accuracy: 0.5760\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9446 - accuracy: 0.5806\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9307 - accuracy: 0.5576\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9200 - accuracy: 0.5714\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9072 - accuracy: 0.6129\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8985 - accuracy: 0.6682\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8885 - accuracy: 0.6406\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8769 - accuracy: 0.6129\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8674 - accuracy: 0.6083\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8597 - accuracy: 0.6359\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8493 - accuracy: 0.6406\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.8412 - accuracy: 0.6313\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8341 - accuracy: 0.6313\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.6544\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8171 - accuracy: 0.6728\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8099 - accuracy: 0.6682\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.8036 - accuracy: 0.6452\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7964 - accuracy: 0.6636\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.6820\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7819 - accuracy: 0.6774\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7760 - accuracy: 0.6682\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7696 - accuracy: 0.6728\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7623 - accuracy: 0.6866\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7582 - accuracy: 0.7235\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.7143\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.6682\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6912\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.7281\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.7005\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.7327\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.7419\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.7143\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 983us/step - loss: 0.7074 - accuracy: 0.7650\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.7834\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 980us/step - loss: 0.6984 - accuracy: 0.7742\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.7143\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.7327\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.7788\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.7742\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.7650\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.7880\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.7880\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.7834\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.7880\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.7926\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.7926\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.7880\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.6436 - accuracy: 0.7972\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.7926\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.7972\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.8018\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.7926\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.8018\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.7972\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.6187 - accuracy: 0.8018\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.8111\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.8065\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 981us/step - loss: 0.6102 - accuracy: 0.8018\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.8111\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 984us/step - loss: 0.6025 - accuracy: 0.8065\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.8065\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.8111\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.8157\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.8065\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.8111\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.8157\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.8203\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.8111\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.5770 - accuracy: 0.8157\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.8157\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.8203\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 989us/step - loss: 0.5682 - accuracy: 0.8157\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 890us/step - loss: 0.5661 - accuracy: 0.8203\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.8295\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.8203\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.8249\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.8295\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 996us/step - loss: 0.5533 - accuracy: 0.8295\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.8295\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.8249\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5467 - accuracy: 0.8341\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.8387\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.8341\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.8341\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 850us/step - loss: 0.5385 - accuracy: 0.8387\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.8341\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.8479\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 931us/step - loss: 0.5325 - accuracy: 0.8387\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 988us/step - loss: 0.5325 - accuracy: 0.8479\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 995us/step - loss: 0.5285 - accuracy: 0.8525\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.8479\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 992us/step - loss: 0.5250 - accuracy: 0.8525\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.8525\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 944us/step - loss: 0.5199 - accuracy: 0.8525\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.8433\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.5168 - accuracy: 0.8387\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.5150 - accuracy: 0.8433\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.8618\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.8525\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8525\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 814us/step - loss: 0.5093 - accuracy: 0.8571\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.8479\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 923us/step - loss: 0.5053 - accuracy: 0.8433\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 988us/step - loss: 0.5035 - accuracy: 0.8618\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8571\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 958us/step - loss: 0.5000 - accuracy: 0.8571\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8571\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.8571\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 890us/step - loss: 0.4956 - accuracy: 0.8571\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8571\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 994us/step - loss: 0.4931 - accuracy: 0.8433\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8571\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.4895 - accuracy: 0.8618\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.8433\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8571\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 990us/step - loss: 0.4861 - accuracy: 0.8664\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8571\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8571\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.8618\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.8571\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 915us/step - loss: 0.4795 - accuracy: 0.8664\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.8618\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8571\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8618\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8618\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.8618\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.8618\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8664\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8618\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.8618\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.4669 - accuracy: 0.8664\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.8664\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8664\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.8664\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.8618\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.8618\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.8664\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.8710\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8664\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8618\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8664\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.8710\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8664\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8664\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8664\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8664\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8664\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8664\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.8664\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8664\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8664\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8664\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.8664\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.8664\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.8664\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8664\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8664\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8664\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8664\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8664\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8664\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.8664\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8710\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8664\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8664\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8710\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8664\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.8664\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8664\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.8664\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8664\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8710\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 977us/step - loss: 0.4260 - accuracy: 0.8710\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8664\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8664\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.8664\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.8710\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8710\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8710\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 917us/step - loss: 0.4225 - accuracy: 0.8710\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2286fb472b0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7f4e10b-81c0-4f71-8f76-3070c9cb9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bbb6b80b-49b2-4bf6-b475-44ab7aa354c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 5)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7c2f6-5c43-4165-9e06-bfac07a86058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4b3e5-c2ef-4552-be07-5c725ad8316c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd10644-9c9c-4f0d-b418-e3d16134a62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95db886e-70ef-442a-9c11-136312c71536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries that we will be using for building the neural network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81f920a7-e4e3-44e7-a0d3-0cb0d1744e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the classes for building the neural network layers\n",
    "from tensorflow.keras.layers import Dense,Input,Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c518c338-bbc2-4aac-a4fa-3f28c76a3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialiezer=tf.keras.initializers.RandomUniform(minval=0.0005, maxval=1, seed=100)\n",
    "\n",
    "input1= Input(shape=1)\n",
    "input2= Input(shape=1)\n",
    "input3= Input(shape=1)\n",
    "input4= Input(shape=1)\n",
    "input5= Input(shape=1)\n",
    "\n",
    "l1=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(input1)\n",
    "l1=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(l1)\n",
    "\n",
    "l2=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(input2)\n",
    "l2=Dense(units=5,use_bias=True,activation='relu',kernel_initializer=initialiezer)(l2)\n",
    "\n",
    "concatted = Concatenate()([l1, l2])\n",
    "out=Dense(units=1,use_bias=True,activation='sigmoid',kernel_initializer=initialiezer)(concatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b41c4c6b-c74c-4172-b69c-4c27dfd78edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c36f426d-585a-4f5c-a65a-3ab7401bd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model([input1,input2,input3,input4,input5],[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c22dfb14-5bb4-4a5e-9cd1-6f3fff781f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "19172477-93a2-43a9-9a29-ad87e671c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Point A   Point B   Point C   Point D   Point E  \\\n",
       "0             0  1.373475  0.958978  0.836790  1.502963  0.978804   \n",
       "1             1  1.940213  1.371291  1.743612  1.315589  2.017418   \n",
       "2             2  1.690368  2.025028  2.025214  1.518278  1.934396   \n",
       "3             3  1.542669  1.888478  1.641450  1.641526  2.550871   \n",
       "4             4  1.429971  1.580948  1.820888  1.274735  1.757213   \n",
       "..          ...       ...       ...       ...       ...       ...   \n",
       "306         306  0.234889  0.341797  0.312052  0.323540  0.359836   \n",
       "307         307  0.235683  0.339810  0.340483  0.328003  0.329723   \n",
       "308         308  0.231840  0.313921  0.329652  0.349243  0.341359   \n",
       "309         309  0.237851  0.306959  0.316966  0.357427  0.358833   \n",
       "310         310  0.234731  0.343230  0.315228  0.321040  0.357567   \n",
       "\n",
       "     Error Classification  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "306                     4  \n",
       "307                     4  \n",
       "308                     4  \n",
       "309                     4  \n",
       "310                     4  \n",
       "\n",
       "[311 rows x 7 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "inputDataFrame=pandas.read_csv(\"../dataset/dataset_with_error_cnn.csv\")\n",
    "inputDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0acd2d71-39cf-47a7-b405-26391db4a7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point A</th>\n",
       "      <th>Point B</th>\n",
       "      <th>Point C</th>\n",
       "      <th>Point D</th>\n",
       "      <th>Point E</th>\n",
       "      <th>Error Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.373475</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.836790</td>\n",
       "      <td>1.502963</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.940213</td>\n",
       "      <td>1.371291</td>\n",
       "      <td>1.743612</td>\n",
       "      <td>1.315589</td>\n",
       "      <td>2.017418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.690368</td>\n",
       "      <td>2.025028</td>\n",
       "      <td>2.025214</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>1.934396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.542669</td>\n",
       "      <td>1.888478</td>\n",
       "      <td>1.641450</td>\n",
       "      <td>1.641526</td>\n",
       "      <td>2.550871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.429971</td>\n",
       "      <td>1.580948</td>\n",
       "      <td>1.820888</td>\n",
       "      <td>1.274735</td>\n",
       "      <td>1.757213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.312052</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.235683</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.329723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.313921</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.349243</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.237851</td>\n",
       "      <td>0.306959</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.343230</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.357567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point A   Point B   Point C   Point D   Point E  Error Classification\n",
       "0    1.373475  0.958978  0.836790  1.502963  0.978804                     0\n",
       "1    1.940213  1.371291  1.743612  1.315589  2.017418                     1\n",
       "2    1.690368  2.025028  2.025214  1.518278  1.934396                     0\n",
       "3    1.542669  1.888478  1.641450  1.641526  2.550871                     1\n",
       "4    1.429971  1.580948  1.820888  1.274735  1.757213                     0\n",
       "..        ...       ...       ...       ...       ...                   ...\n",
       "306  0.234889  0.341797  0.312052  0.323540  0.359836                     4\n",
       "307  0.235683  0.339810  0.340483  0.328003  0.329723                     4\n",
       "308  0.231840  0.313921  0.329652  0.349243  0.341359                     4\n",
       "309  0.237851  0.306959  0.316966  0.357427  0.358833                     4\n",
       "310  0.234731  0.343230  0.315228  0.321040  0.357567                     4\n",
       "\n",
       "[311 rows x 6 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDataFrame = inputDataFrame.drop('Unnamed: 0', axis=1)\n",
    "inputDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7cfca-edad-4a01-819e-005c84df144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e520853-0d5a-4625-86be-e68a8f67ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data out as numpy arrays\n",
    "x1s=inputDataFrame['Point A'].to_numpy()\n",
    "x2s=inputDataFrame['Point B'].to_numpy()\n",
    "x3s=inputDataFrame['Point C'].to_numpy()\n",
    "x4s=inputDataFrame['Point D'].to_numpy()\n",
    "x5s=inputDataFrame['Point E'].to_numpy()\n",
    "ys=inputDataFrame['Error Classification'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d0b1235a-01b4-4b15-a964-e46fffdde6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1s=x1s.reshape(x1s.shape[0],1)\n",
    "x2s=x2s.reshape(x2s.shape[0],1)\n",
    "x3s=x3s.reshape(x3s.shape[0],1)\n",
    "x4s=x4s.reshape(x4s.shape[0],1)\n",
    "x5s=x5s.reshape(x5s.shape[0],1)\n",
    "ys=ys.reshape(ys.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "16ec04b5-e74e-4bdd-a4e7-20aa8d25e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1Train, x1Test, x2Train, x2Test, x3Train, x3Test, x4Train, x4Test, x5Train, x5Test, yTrain, yTest = train_test_split(x1s,x2s,x3s,x4s,x5s,ys, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "44d78994-105a-4afa-a231-e5b31fb23647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of x1Train = (248, 1)\n",
      "the shape of x1Test = (63, 1)\n",
      "the shape of x2Train = (248, 1)\n",
      "the shape of x2Test = (63, 1)\n",
      "the shape of x3Train = (248, 1)\n",
      "the shape of x3Test = (63, 1)\n",
      "the shape of x4Train = (248, 1)\n",
      "the shape of x4Test = (63, 1)\n",
      "the shape of x5Train = (248, 1)\n",
      "the shape of x5Test = (63, 1)\n",
      "the shape of yTrain = (248, 1)\n",
      "the shape of yTest = (63, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'the shape of x1Train = {x1Train.shape}')\n",
    "print(f'the shape of x1Test = {x1Test.shape}')\n",
    "\n",
    "print(f'the shape of x2Train = {x5Train.shape}')\n",
    "print(f'the shape of x2Test = {x5Test.shape}')\n",
    "\n",
    "print(f'the shape of x3Train = {x5Train.shape}')\n",
    "print(f'the shape of x3Test = {x5Test.shape}')\n",
    "\n",
    "print(f'the shape of x4Train = {x5Train.shape}')\n",
    "print(f'the shape of x4Test = {x5Test.shape}')\n",
    "\n",
    "print(f'the shape of x5Train = {x5Train.shape}')\n",
    "print(f'the shape of x5Test = {x5Test.shape}')\n",
    "\n",
    "\n",
    "print(f'the shape of yTrain = {yTrain.shape}')\n",
    "print(f'the shape of yTest = {yTest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "57fc65ca-6e78-4dbb-85f6-477e9845d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',metrics=['mse'],optimizer=tf.optimizers.Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "de093d4a-1694-41d8-9ce8-ee908193fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "#     metrics = ['accuracy']\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b070f7f5-db02-4a6e-a927-f650b35b8cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 4.6377 - mse: 4.6377 - val_loss: 4.1628 - val_mse: 4.1628\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5607 - mse: 4.5607 - val_loss: 4.1011 - val_mse: 4.1011\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4884 - mse: 4.4884 - val_loss: 4.0452 - val_mse: 4.0452\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4223 - mse: 4.4223 - val_loss: 3.9959 - val_mse: 3.9959\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3636 - mse: 4.3636 - val_loss: 3.9536 - val_mse: 3.9536\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3128 - mse: 4.3128 - val_loss: 3.9184 - val_mse: 3.9184\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2701 - mse: 4.2701 - val_loss: 3.8897 - val_mse: 3.8897\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2351 - mse: 4.2351 - val_loss: 3.8670 - val_mse: 3.8670\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.2070 - mse: 4.2070 - val_loss: 3.8492 - val_mse: 3.8492\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1849 - mse: 4.1849 - val_loss: 3.8357 - val_mse: 3.8357\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.1679 - mse: 4.1679 - val_loss: 3.8254 - val_mse: 3.8254\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1549 - mse: 4.1549 - val_loss: 3.8177 - val_mse: 3.8177\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1450 - mse: 4.1450 - val_loss: 3.8119 - val_mse: 3.8119\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1376 - mse: 4.1376 - val_loss: 3.8077 - val_mse: 3.8077\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1320 - mse: 4.1320 - val_loss: 3.8045 - val_mse: 3.8045\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1278 - mse: 4.1278 - val_loss: 3.8021 - val_mse: 3.8021\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1246 - mse: 4.1246 - val_loss: 3.8003 - val_mse: 3.8003\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1222 - mse: 4.1222 - val_loss: 3.7989 - val_mse: 3.7989\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1204 - mse: 4.1204 - val_loss: 3.7979 - val_mse: 3.7979\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1190 - mse: 4.1190 - val_loss: 3.7971 - val_mse: 3.7971\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1179 - mse: 4.1179 - val_loss: 3.7965 - val_mse: 3.7965\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1171 - mse: 4.1171 - val_loss: 3.7960 - val_mse: 3.7960\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1164 - mse: 4.1164 - val_loss: 3.7956 - val_mse: 3.7956\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1159 - mse: 4.1159 - val_loss: 3.7953 - val_mse: 3.7953\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1155 - mse: 4.1155 - val_loss: 3.7951 - val_mse: 3.7951\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1151 - mse: 4.1151 - val_loss: 3.7949 - val_mse: 3.7949\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1148 - mse: 4.1148 - val_loss: 3.7948 - val_mse: 3.7948\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1146 - mse: 4.1146 - val_loss: 3.7946 - val_mse: 3.7946\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1144 - mse: 4.1144 - val_loss: 3.7945 - val_mse: 3.7945\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1143 - mse: 4.1143 - val_loss: 3.7944 - val_mse: 3.7944\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1141 - mse: 4.1141 - val_loss: 3.7944 - val_mse: 3.7944\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1140 - mse: 4.1140 - val_loss: 3.7943 - val_mse: 3.7943\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1139 - mse: 4.1139 - val_loss: 3.7942 - val_mse: 3.7942\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1138 - mse: 4.1138 - val_loss: 3.7942 - val_mse: 3.7942\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1138 - mse: 4.1138 - val_loss: 3.7942 - val_mse: 3.7942\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1137 - mse: 4.1137 - val_loss: 3.7941 - val_mse: 3.7941\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1137 - mse: 4.1137 - val_loss: 3.7941 - val_mse: 3.7941\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1136 - mse: 4.1136 - val_loss: 3.7941 - val_mse: 3.7941\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1136 - mse: 4.1136 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1135 - mse: 4.1135 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7940 - val_mse: 3.7940\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1134 - mse: 4.1134 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7939 - val_mse: 3.7939\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1133 - mse: 4.1133 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1132 - mse: 4.1132 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7938 - val_mse: 3.7938\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1131 - mse: 4.1131 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1130 - mse: 4.1130 - val_loss: 3.7937 - val_mse: 3.7937\n"
     ]
    }
   ],
   "source": [
    "# train the model. just run a few epochs for this test run. you can adjust later.\n",
    "history=model.fit(x=[x1Train,x2Train,x3Train,x4Train,x5Train],y=[yTrain],validation_data=([x1Test,x2Test,x3Test,x4Test,x5Test],[yTest]),batch_size=256, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6a74b73d-a935-4795-95bd-ec067da459c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "input=[x1Test[60],x2Test[60],x3Test[60],x4Test[60],x4Test[60]]\n",
    "output=model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ad62dad-b2dd-4eb0-b4ef-ea276d76a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.78251585]),\n",
       " array([2.98232124]),\n",
       " array([2.37517084]),\n",
       " array([2.83734284]),\n",
       " array([2.83734284])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf4e1347-bfd3-41ca-bb38-4796a0cc9a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b9e49fd0-f811-4471-a1ef-394741df8d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34060b4-bf10-41eb-96e3-e4f9684598b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpds",
   "language": "python",
   "name": "mlpds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
